## 构建第一个神经网络
------

1 关系拟合 (回归)

**构建数据**

我们创建一些假数据来模拟真实的情况. 比如一个一元二次函数: y = a * x^2 + b, 我们给 y 数据加上一点噪声来更加真实的展示它.

**建立神经网络** 

建立一个神经网络我们可以直接运用 torch 中的体系. 先定义所有的层属性(__init__()), 然后再一层层搭建(forward(x))层于层的关系链接. 

**训练网络**
训练网络模型 学习模型参数

**可视化训练过程** 
为了可视化整个训练的过程, 更好的理解是如何训练
 
[具体代码参考](./Net.py)
 
2 变量 (Variable)

**什么是变量**
'''
在 Torch 中的 Variable 就是一个存放会变化的值的地理位置. 里面的值会不停的变化. 就像一个裝鸡蛋的篮子, 鸡蛋数会不停变动. 
那谁是里面的鸡蛋呢, 自然就是 Torch 的 Tensor 咯. 如果用一个 Variable 进行计算, 那返回的也是一个同类型的 Variable.
''

**Variable 计算, 梯度** 
'''
时刻记住, Variable 计算时, 它在背景幕布后面一步步默默地搭建着一个庞大的系统, 叫做计算图, computational graph. 这个图是用来干嘛的? 
原来是将所有的计算步骤 (节点) 都连接起来, 最后进行误差反向传递的时候, 一次性将所有 variable 里面的修改幅度 (梯度) 都计算出来, 
而 tensor 就没有这个能力啦.
'''

3 激励函数 (Activation)

**Torch 中的激励函数** 

Torch 中的激励函数有很多, 不过我们平时要用到的就这几个. relu, sigmoid, tanh, softplus.


